
# ðŸ§  Detection Bypass Strategy â€” HumanTextAI

## ðŸŽ¯ Objective
Design a modular and scalable humanization engine that transforms AI-generated text into human-like writing with the following constraints:

- **Detection Confidence**: Reduce AI detection scores to **< 20%**
- **Semantic Integrity**: Preserve **â‰¥ 90%** of original meaning
- **Performance**: Processing time **< 10s per 1000 words**
- **Deployment-Ready**: Usable via CLI and API (FastAPI)

---

## ðŸ” Core Problem

Modern AI detectors (GPTZero, Turnitin, QuillBot) identify machine-generated text using patterns such as:
- Low perplexity (predictability)
- Low burstiness (uniform sentence structures)
- Repetitive phrasing and unnatural flow

---

## ðŸ§© Transformation Pipeline Overview

[ Input Text ]
      â†“
[ Cleaning & Preprocessing ]
      â†“
[ Modular Rewriting Engine ]
      â†“
[ Semantic Validation ]
      â†“
[ Final Humanized Output ]

---

## ðŸ§° Transformation Modules

| Module | Purpose | Key Actions |
|--------|---------|-------------|
| **Lexical Substitution** | Increase lexical diversity | Synonym replacement, paraphrase noun/adjective phrases |
| **Sentence Restructuring** | Enhance burstiness | Flip clause order, change passive â†” active, combine/split sentences |
| **Stylistic Noise Injection** | Mimic human unpredictability | Insert rhetorical phrases, idioms, randomness in tone |
| **Semantic Similarity Validation** | Maintain meaning | Use sentence-transformers + cosine similarity threshold |
| **Readability Tuner** | Balance complexity | Use `textstat` to keep writing readable but less robotic |

---

## ðŸŽ›ï¸ Humanization Level (1â€“10)

| Level | Description |
|-------|-------------|
| 1â€“3   | Light: Subtle paraphrasing, high fidelity |
| 4â€“7   | Balanced: Mid-level rewrites with tone shifts |
| 8â€“10  | Aggressive: Max burstiness + complete sentence refactoring |

---

## ðŸ§ª Quality Control Metrics

| Metric           | Threshold          | Tooling |
|------------------|--------------------|---------|
| AI Detection Score | < 20%             | GPTZero API, Turnitin trials |
| Semantic Similarity | â‰¥ 90% cosine sim | `sentence-transformers` |
| Grammar Quality    | High (no loss)    | `language-tool-python` |
| Readability Index  | 50â€“70 Flesch      | `textstat` |

---

## ðŸ”„ Feedback Loop

If detection score â‰¥ 20%:
- Re-run pipeline with higher intensity level
- Swap paraphrasing templates
- Adjust randomness parameters

---

## ðŸ“Œ Implementation Notes

- All modules are **independent and testable**
- Final transformation passes are scored before writing output
- Intermediate outputs are logged for rollback or debugging
- CLI + FastAPI support baked in from the start

---

## ðŸ§± Dependencies (Initial)

- `spacy` for parsing and structure detection
- `nltk`, `textstat` for lexical/sentence analysis
- `sentence-transformers` for semantic checks
- `parrot-paraphraser` or T5-based paraphrasing for rewriting
- `language-tool-python` for grammar QA

---

## âœ… Next Steps

- [ ] Collect AI vs. Human text samples into `data/examples/`
- [ ] Design core rewriter modules inside `rewriter.py`
- [ ] Build evaluation harness to test bypass success
